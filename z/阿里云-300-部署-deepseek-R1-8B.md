---
tags: [type/howto, status/evergreen]
description: 如何xxx
created: 2025-12-30T21:41:24
updated: 2025-12-30T21:42:01
---

# 阿里云-300-部署-deepseek-R1-8B 

使用 300 元阿里云学生代金券部署 **DeepSeek-R1-Distill-Qwen-8B** 是一个非常完美的实践项目。8B 模型的显存需求大约在 5GB-8GB（量化后），这使得我们可以选择性价比极高的 GPU 实例。

以下是针对学生券优化的**全流程实操方案**，核心思路是：**抢占式实例 + Ollama + Open WebUI**。

---

### 第一步：创建阿里云 GPU 服务器 (ECS)

为了节省资金，我们必须使用**抢占式实例**。

1. **进入 ECS 购买页：** 选择“自定义购买”。
2. **付费模式：** 勾选 **“抢占式实例”**（价格通常是按量的 1-3 折）。
3. **地域：** 建议选 **华北 6 (呼和浩特)** 或 **华北 3 (张家口)**，GPU 资源较多且便宜。
4. **实例规格：**
* 搜索并选择 **`ecs.gn6i-c4g1.xlarge`** (NVIDIA T4，16G 显存，约 1.2 元/小时)。
* 或者 **`ecs.gn7i-c8g1.2xlarge`** (NVIDIA A10，24G 显存，约 2.2 元/小时)。
* *注：8B 模型 T4 显卡完全够用，16G 显存还能让你以后尝试 14B 模型。*

5. **镜像：** 选择 **公共镜像 -> Ubuntu 22.04**，勾选 **“安装 GPU 驱动”**，驱动版本选默认最新即可。
6. **存储：** 系统盘选 **ESSD**，容量设置为 **100GB**（模型和 Docker 镜像很占空间）。
7. **带宽：** 选 **“按使用流量”**，峰值拉到 **100Mbps**（下载模型快，不求人）。
8. **购买：** 确认下单。

---

### 第二步：配置安全组（开门）

在 ECS 控制台找到你的实例，进入“安全组”配置规则，手动添加：

* **端口 3000：** 给 Open WebUI（网页界面）用。
* **端口 11434：** 给 Ollama API 用（如果你想在本地调用服务器接口）。

---

### 第三步：环境准备（连接服务器）

使用终端（或阿里云自带的远程连接 Workbench）登录服务器。

1. **检查 GPU 状态：**

```bash
nvidia-smi

```

看到显卡信息说明驱动安装成功。
2. **安装 Docker：** (用于运行前端界面)

```bash
curl -fsSL https://get.docker.com | bash -s docker

```

---

### 第四步：部署推理后端（Ollama）

Ollama 是目前部署 DeepSeek 蒸馏版最简单、最快的工具。

1. **安装 Ollama：**

```bash
curl -fsSL https://ollama.com/install.sh | sh

```

2. **运行 DeepSeek-R1-8B：**

```bash
ollama run deepseek-r1:8b

```

*系统会自动开始下载模型。下载完成后，你直接在终端就可以开始对话了。输入 `/bye` 退出。*

---

### 第五步：部署图形化界面（Open WebUI）

为了获得类似 ChatGPT 的网页体验，我们部署 Open WebUI。

1. **运行 Docker 容器：**

```bash
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main

```

2. **访问界面：**
打开浏览器，输入 `你的服务器公网IP:3000`。
3. **注册与登录：**
第一次进入需要注册一个管理员账号（这个账号只存在于你的服务器上）。
4. **选择模型：**
在页面上方的模型列表里选择 `deepseek-r1:8b`，即可开始沉浸式对话。

---

### 💰 财务省钱策略（非常重要！）

由于你只有 300 元，如果不注意，几天就会扣完。请务必遵守以下操作：

1. **不用即释放：**
* 学生券买的 ECS 是按小时扣费的。当你**不需要实验时**，在控制台点击 **“释放实例”**（释放后服务器会消失，不再扣费）。

2. **保存成果（快照/镜像）：**
* 释放前，给系统盘打一个 **“快照”** 或创建 **“自定义镜像”**（费用极低，每月几块钱）。
* 下次想玩时，用这个镜像重新买一台抢占式实例，以前装好的环境、下载好的模型都在，**5分钟恢复战斗**。

3. **流量开销：**
* 下载模型会产生流量费。DeepSeek-8B 约 5GB，流量费约 4 元。尽量减少重复下载的次数。

### 总结方案优势

* **配置：** gn6i (T4) 实例，16G 显存。
* **模型：** DeepSeek-R1-Distill-Qwen-8B。
* **预估成本：** 实例 1.2元/时 + 流量 0.8元/GB。
* **体验：** 满速 100Mbps 响应，拥有独立的 ChatGPT 风格网页，支持逻辑推理思维链显示。

这个流程走下来，你不仅学会了如何操作云资源，还掌握了目前最主流的大模型私有化部署工具链。